
# ğŸš€ Setup Local - Service ML EcoTrajet

Guide complet pour installer et lancer le service de Machine Learning en local.

## ğŸ“‹ PrÃ©requis

- Python 3.9+
- pip ou conda
- AccÃ¨s Ã  la base de donnÃ©es Supabase (credentials configurÃ©s)

## ğŸ”§ Installation

### 1. Navigation et installation des dÃ©pendances
```bash
cd ml_service
pip install -r requirements.txt
```

### 2. Configuration de l'environnement
```bash
# Copier le fichier d'exemple
cp .env.example .env

# Ã‰diter le fichier .env avec vos credentials Supabase
# SUPABASE_URL=https://knebskomwvvvoaclrwjv.supabase.co
# SUPABASE_KEY=your_anon_key_here
```

## ğŸ¯ Ordre d'exÃ©cution OBLIGATOIRE

### Ã‰tape 1 : EntraÃ®nement des modÃ¨les (PREMIÃˆRE FOIS)
```bash
python scripts/train_models.py
```
**âš ï¸ IMPORTANT :** Cette Ã©tape est **OBLIGATOIRE** avant de lancer l'API car les modÃ¨les n'existent pas encore !

**Ce script va :**
- Charger les donnÃ©es historiques depuis Supabase
- EntraÃ®ner le modÃ¨le LSTM pour les prÃ©dictions VÃ©lib'
- EntraÃ®ner le modÃ¨le Prophet pour l'analyse des tendances
- EntraÃ®ner le modÃ¨le Random Forest pour les calculs carbone
- Sauvegarder tous les modÃ¨les dans `/models/`

### Ã‰tape 2 : Ã‰valuation des modÃ¨les (OPTIONNEL)
```bash
python scripts/evaluate_models.py
```
GÃ©nÃ¨re des rapports de performance et des mÃ©triques.

### Ã‰tape 3 : Lancement de l'API
```bash
uvicorn api.main:app --reload --host 0.0.0.0 --port 8000
```

**API disponible sur :** http://localhost:8000

## ğŸ§ª Test de l'API

### Endpoints disponibles :
- **Health check :** `GET http://localhost:8000/health`
- **PrÃ©dictions VÃ©lib' :** `POST http://localhost:8000/api/v1/predict/velib-availability`
- **Analyse tendances :** `POST http://localhost:8000/api/v1/analyze/trends`
- **Calcul carbone :** `POST http://localhost:8000/api/v1/calculate/carbon-footprint`

### Test rapide :
```bash
curl http://localhost:8000/health
```

## ğŸ“Š DÃ©veloppement avec Jupyter

### Lancer Jupyter pour analyser les donnÃ©es :
```bash
jupyter notebook --ip=0.0.0.0 --port=8888 --no-browser
```

**Notebooks disponibles :**
- `notebooks/data_exploration.ipynb` - Exploration des donnÃ©es
- `notebooks/velib_analysis.ipynb` - Analyse spÃ©cifique VÃ©lib'
- `notebooks/carbon_modeling.ipynb` - ModÃ©lisation carbone

## ğŸ³ Alternative : Docker

Si vous prÃ©fÃ©rez utiliser Docker :

```bash
# Lancer tout avec Docker Compose
docker-compose up --build

# Ou sÃ©parÃ©ment :
# API ML sur port 8000
docker-compose up ml-api

# Jupyter sur port 8888  
docker-compose up jupyter
```

## ğŸ”„ Workflow de dÃ©veloppement

### PremiÃ¨re installation :
1. `pip install -r requirements.txt`
2. Configurer `.env`
3. **`python scripts/train_models.py`** (OBLIGATOIRE)
4. `uvicorn api.main:app --reload`

### DÃ©veloppement quotidien :
1. `uvicorn api.main:app --reload` (si les modÃ¨les existent dÃ©jÃ )
2. Modifier le code
3. Tester l'API

### Re-entraÃ®nement (si nouvelles donnÃ©es) :
1. `python scripts/train_models.py`
2. `python scripts/evaluate_models.py` (optionnel)
3. RedÃ©marrer l'API

## ğŸ“ Structure des fichiers gÃ©nÃ©rÃ©s

AprÃ¨s l'entraÃ®nement, vous aurez :
```
models/
â”œâ”€â”€ velib_lstm_model.h5           # ModÃ¨le LSTM VÃ©lib'
â”œâ”€â”€ velib_scaler_x.pkl            # Scaler features
â”œâ”€â”€ velib_scaler_y.pkl            # Scaler targets  
â”œâ”€â”€ trends_prophet_model.pkl      # ModÃ¨le Prophet
â”œâ”€â”€ carbon_rf_model.pkl           # ModÃ¨le Random Forest
â””â”€â”€ training_report_*.json        # Rapports d'entraÃ®nement
```

## âš ï¸ Troubleshooting

### Erreur "ModÃ¨le non trouvÃ©" :
â†’ Vous devez d'abord exÃ©cuter `python scripts/train_models.py`

### Erreur de connexion Supabase :
â†’ VÃ©rifiez votre fichier `.env` avec les bons credentials

### Erreur de dÃ©pendances :
â†’ `pip install -r requirements.txt --upgrade`

### L'API ne dÃ©marre pas :
â†’ VÃ©rifiez que le port 8000 est libre : `lsof -i :8000`

---

**ğŸ‰ Une fois l'API lancÃ©e, elle sera prÃªte Ã  recevoir les requÃªtes depuis l'application principale EcoTrajet !**
